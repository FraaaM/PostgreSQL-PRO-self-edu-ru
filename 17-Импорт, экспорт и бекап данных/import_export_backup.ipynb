{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262aafa8",
   "metadata": {},
   "source": [
    "## 1\\. Выбор правильного инструмента для задачи\n",
    "\n",
    "### Ключевые различия\n",
    "\n",
    "  * **`COPY` vs `\\copy`:** Это самый частый источник путаницы.\n",
    "\n",
    "      * **`COPY`** — это команда SQL, выполняемая **на сервере PostgreSQL**. Сервер должен иметь прямой доступ к файлу для чтения или записи. Это требует прав суперпользователя или членства в специальных ролях (`pg_read_server_files`, `pg_write_server_files`). Она невероятно быстра, так как работает на уровне файловой системы сервера.\n",
    "      * **`\\copy`** — это мета-команда клиента `psql`. Она выполняется **на клиентской машине**, где запущен `psql`. `psql` читает файл с вашего локального диска, передает данные на сервер через стандартное соединение, а затем сервер выполняет `COPY FROM STDIN`. Это универсальный и безопасный способ, не требующий прав на сервере.\n",
    "\n",
    "  * **`COPY`/`\\copy` vs `pg_dump`/`pg_restore`:** Разница в назначении.\n",
    "\n",
    "      * **`COPY`/`\\copy`** предназначены для **перемещения сырых данных** в одну таблицу или из нее. Они не знают ничего о структуре таблицы (кроме порядка столбцов), индексах, триггерах или внешних ключах. Это просто транспорт для данных.\n",
    "      * **`pg_dump`/`pg_restore`** — это утилиты для **логического резервного копирования**. `pg_dump` извлекает не только данные, но и DDL-команды для воссоздания схемы: таблицы, представления, индексы, роли, права доступа и т.д. Это инструмент для создания полноценной, консистентной копии базы данных или ее частей.\n",
    "\n",
    "  * **Текстовые форматы (CSV, TEXT) vs Бинарный формат vs Custom Format (`-Fc`)**\n",
    "\n",
    "      * **Текстовые (CSV, TEXT):** Человекочитаемые, универсальные форматы. Идеальны для обмена данными с другими системами (Excel, Python/Pandas, BI-инструменты). CSV более гибок за счет опций (заголовки, разделители).\n",
    "      * **Бинарный (`COPY BINARY`):** Максимально быстрый, но непереносимый формат. Он зависит от архитектуры машины и версии PostgreSQL. Используется для быстрой миграции данных между идентичными серверами.\n",
    "      * **Custom Format (`-Fc` для `pg_dump`):** \"Золотой стандарт\" для бэкапов. Это сжатый, бинарный формат, который включает в себя и схему, и данные. Его главное преимущество — гибкость при восстановлении (`pg_restore`): можно восстанавливать базу параллельно, выбирать отдельные таблицы или только схему.\n",
    "\n",
    "### Таблица-решение: Быстрый выбор инструмента\n",
    "\n",
    "| Задача | Рекомендуемый инструмент | Формат | Пример команды и обоснование |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Выгрузить данные таблицы для анализа в Excel** | `\\copy` | CSV | `\\copy (SELECT * FROM sales) TO 'sales.csv' WITH CSV HEADER;`\\<br\\> *Клиентская команда, создает CSV с заголовками, идеально для Excel.* |\n",
    "| **Быстро загрузить большой CSV-файл с сервера** | `COPY` | CSV | `COPY users FROM '/var/lib/postgresql/data/users.csv' WITH CSV;`\\<br\\> *Максимальная скорость, файл уже на сервере.* |\n",
    "| **Создать полный бэкап базы данных для восстановления** | `pg_dump` | Custom (`-Fc`) | `pg_dump -Fc -U postgres mydb > mydb.dump`\\<br\\> *Сжатый, надежный формат, позволяет параллельное и выборочное восстановление.* |\n",
    "| **Перенести схему (без данных) в другую БД** | `pg_dump` | Plain (`-p`) | `pg_dump -s -U postgres mydb > schema.sql`\\<br\\> *Создает текстовый SQL-файл, который легко читать и редактировать.* |\n",
    "| **Восстановить одну таблицу из полного бэкапа** | `pg_restore` | Custom (`-Fc`) | `pg_restore -t my_table -d new_db mydb.dump`\\<br\\> *Главное преимущество формата `-Fc` — выборочное восстановление.* |\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. Фундамент: Команды COPY и \\\\copy\n",
    "\n",
    "Это рабочие лошадки для ежедневных задач импорта/экспорта.\n",
    "\n",
    "### Детальный разбор синтаксиса\n",
    "Для терминала Windows следует удалить запись  `| STDOUT`   из команды\n",
    "```sql\n",
    "-- Экспорт данных ИЗ таблицы В файл\n",
    "COPY table_name [(column1, column2, ...)] TO 'filename' WITH (options);\n",
    "\n",
    "-- Импорт данных В таблицу ИЗ файла\n",
    "COPY table_name [(column1, column2, ...)] FROM 'filename' WITH (options);\n",
    "```\n",
    "\n",
    "  * `table_name`: Целевая таблица.\n",
    "  * `[(column1, ...)]`: Опциональный список столбцов. Позволяет указать, какие столбцы и в каком порядке выгружать/загружать.\n",
    "  * `TO|FROM`: Направление операции.\n",
    "  * `'filename'` : Источник или приемник. `'filename'` — путь к файлу **на сервере**.\n",
    "  * `WITH (options)`: Блок для указания формата и его параметров.\n",
    "\n",
    "### Форматы и опции (с примерами)\n",
    "\n",
    "Предположим, у нас есть таблица:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE employees (\n",
    "    id INT PRIMARY KEY,\n",
    "    full_name TEXT NOT NULL,\n",
    "    department TEXT,\n",
    "    salary NUMERIC(10, 2),\n",
    "    hire_date DATE\n",
    ");\n",
    "```\n",
    "\n",
    "#### **CSV (Comma-Separated Values)**\n",
    "\n",
    "Самый гибкий текстовый формат.\n",
    "\n",
    "  * `HEADER`: Указывает, что первая строка файла является заголовком. При импорте эта строка пропускается, при экспорте — добавляется.\n",
    "  * `DELIMITER ','`: Задает разделитель полей (по умолчанию запятая). Можно использовать любой символ, например `';'` или `'|'`.\n",
    "  * `QUOTE '\"'`: Символ для обрамления значений, содержащих разделитель или спецсимволы.\n",
    "  * `ESCAPE '\\'`: Символ для экранирования символа кавычки внутри значения.\n",
    "  * `NULL ''`: Указывает, как представлять `NULL`-значения в файле. По умолчанию это `\\N`. Пустая строка (`''`) — частый выбор.\n",
    "\n",
    "**Пример экспорта в CSV:**\n",
    "\n",
    "```sql\n",
    "\\copy employees TO 'employees.csv' WITH (FORMAT CSV, HEADER, DELIMITER ';', NULL 'N/A');\n",
    "-- или \n",
    "COPY employees TO 'D:\\employee.csv' WITH (FORMAT CSV, HEADER, DELIMITER ';', NULL 'N/A');\n",
    "```\n",
    "\n",
    "*Результат в `employees.csv`:*\n",
    "\n",
    "```csv\n",
    "id;full_name;department;salary;hire_date\n",
    "1;John Doe;Engineering;75000.00;2022-01-15\n",
    "2;Jane Smith;Marketing;N/A;2023-03-10\n",
    "```\n",
    "\n",
    "**Пример импорта из CSV:**\n",
    "\n",
    "```sql\n",
    "-- Сначала очистим таблицу для чистоты эксперимента\n",
    "TRUNCATE employees;\n",
    "\n",
    "\\copy employees FROM 'employees.csv' WITH (FORMAT CSV, HEADER, DELIMITER ';', NULL 'N/A');\n",
    "```\n",
    "\n",
    "#### **TEXT (Текстовый формат по умолчанию)**\n",
    "\n",
    "Простой формат, где разделителем по умолчанию является символ табуляции (`\\t`).\n",
    "\n",
    "**Пример экспорта в TEXT:**\n",
    "\n",
    "```sql\n",
    "\\copy employees TO 'employees.txt'; -- FORMAT TEXT можно опустить, это дефолт\n",
    "```\n",
    "\n",
    "*Результат в `employees.txt` (пробелы здесь — это табуляция):*\n",
    "\n",
    "```\n",
    "1   John Doe    Engineering 75000.00    2022-01-15\n",
    "2   Jane Smith  Marketing   \\N          2023-03-10\n",
    "```\n",
    "\n",
    "### Работа с подмножествами данных\n",
    "\n",
    "Часто нужно выгрузить не всю таблицу.\n",
    "\n",
    "  * **Выборочные столбцы и строки (Экспорт):** Используйте `COPY` с подзапросом `SELECT`.\n",
    "    ```sql\n",
    "    \\copy (SELECT full_name, salary FROM employees WHERE department = 'Engineering') TO 'engineers.csv' WITH CSV HEADER;\n",
    "    ```\n",
    "  * **Выборочные столбцы (Импорт):** Укажите список столбцов после имени таблицы.\n",
    "    ```sql\n",
    "    -- CSV файл 'new_hires.csv' содержит только имя и зарплату\n",
    "    -- full_name,salary\n",
    "    -- \"Alice Wonderland\",60000.00\n",
    "\n",
    "    -- Загружаем данные, указывая, в какие столбцы их класть. `id` будет сгенерирован, если это SERIAL.\n",
    "    \\copy employees(full_name, salary) FROM 'new_hires.csv' WITH CSV HEADER;\n",
    "    ```\n",
    "\n",
    "-----\n",
    "\n",
    "## 3\\. Профессиональная обработка ошибок и валидация данных\n",
    "\n",
    "При работе с реальными данными ошибки неизбежны: неверный формат даты, нарушение ограничений и т.д. `COPY` по умолчанию работает по принципу \"все или ничего\" — одна ошибка, и вся операция откатывается.\n",
    "\n",
    "### Стратегия промежуточной таблицы (Staging Table) — лучшая практика\n",
    "\n",
    "Это самый надежный и гибкий подход к импорту \"грязных\" данных.\n",
    "\n",
    "1.  **Создаем Staging-таблицу:** Структура этой таблицы повторяет структуру CSV-файла, но **все столбцы имеют тип `TEXT`**. Это гарантирует, что `COPY` примет любые данные без ошибок типов.\n",
    "\n",
    "    ```sql\n",
    "    CREATE TEMP TABLE employees_staging (\n",
    "        id TEXT,\n",
    "        full_name TEXT,\n",
    "        department TEXT,\n",
    "        salary TEXT,\n",
    "        hire_date TEXT\n",
    "    );\n",
    "    ```\n",
    "\n",
    "    *Использование `TEMP TABLE` удобно, так как таблица будет автоматически удалена в конце сессии.*\n",
    "\n",
    "2.  **Загружаем сырые данные:** Выполняем `COPY` в эту промежуточную таблицу. Этот шаг практически никогда не падает.\n",
    "\n",
    "    ```sql\n",
    "    \\copy employees_staging FROM 'dirty_data.csv' WITH CSV HEADER;\n",
    "    ```\n",
    "\n",
    "3.  **Валидация и очистка с помощью SQL:** Теперь, когда данные в базе, мы можем использовать всю мощь SQL для их проверки, очистки, преобразования и вставки в целевую таблицу.\n",
    "\n",
    "    ```sql\n",
    "    INSERT INTO employees (id, full_name, department, salary, hire_date)\n",
    "    SELECT\n",
    "        CAST(NULLIF(id, '') AS INT),\n",
    "        full_name,\n",
    "        NULLIF(department, 'N/A'), -- Превращаем 'N/A' в NULL\n",
    "        CAST(REPLACE(salary, '$', '') AS NUMERIC), -- Убираем знаки валют\n",
    "        TO_DATE(hire_date, 'MM/DD/YYYY') -- Преобразуем формат даты\n",
    "    FROM\n",
    "        employees_staging\n",
    "    -- Отсеиваем строки с явными ошибками, которые не можем исправить\n",
    "    WHERE\n",
    "        id ~ '^[0-9]+$' -- Проверяем, что ID - это число\n",
    "        AND full_name IS NOT NULL;\n",
    "    ```\n",
    "\n",
    "    **Почему это лучшая практика?**\n",
    "\n",
    "      * **Изоляция ошибок:** `COPY` успешно завершается, а \"плохие\" строки остаются в `staging` таблице для анализа.\n",
    "      * **Сложные преобразования:** Вы можете выполнять любую логику на SQL, которую невозможно выразить в опциях `COPY`.\n",
    "      * **Аудит и отладка:** Легко найти и проанализировать строки, которые не прошли валидацию.\n",
    "\n",
    "### Управление транзакциями\n",
    "\n",
    "Для гарантии атомарности операции импорта, всегда оборачивайте `COPY` в транзакцию.\n",
    "\n",
    "```sql\n",
    "BEGIN;\n",
    "TRUNCATE employees; -- Опционально, если нужно перезаписать данные\n",
    "\\copy employees FROM 'employees.csv' WITH CSV;\n",
    "COMMIT;\n",
    "-- Если на этапе \\copy произойдет ошибка, транзакция автоматически прервется,\n",
    "-- и TRUNCATE будет отменен (ROLLBACK). Таблица останется в исходном состоянии.\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## 4\\. Оптимизация производительности для больших объемов данных\n",
    "\n",
    "`COPY` — это самый быстрый способ загрузки данных в PostgreSQL. Давайте разберемся, как сделать его еще быстрее.\n",
    "\n",
    "### Почему `COPY` быстрый?\n",
    "\n",
    "`COPY` работает на низком уровне, минуя значительную часть накладных расходов SQL-парсера и планировщика. При определенных условиях (например, загрузка в пустую таблицу, созданную в той же транзакции) он может минимизировать запись в WAL (Write-Ahead Log), что дает колоссальный прирост скорости.\n",
    "\n",
    "### Ключевые техники оптимизации\n",
    "\n",
    "1.  **Обертывание в одну транзакцию:** Как уже упоминалось, `BEGIN; COPY ...; COMMIT;` не только обеспечивает атомарность, но и снижает накладные расходы на управление транзакциями для каждой строки.\n",
    "\n",
    "2.  **Манипуляции с индексами и ограничениями (самый важный пункт\\!):**\n",
    "\n",
    "      * **Что делать:** Перед началом большого импорта (`COPY` на миллионы строк) **удалите все индексы (кроме Primary Key, если он не нужен для проверок), внешние ключи (Foreign Keys) и триггеры** с целевой таблицы.\n",
    "      * **Почему это работает:**\n",
    "          * **Индексы:** При вставке каждой строки PostgreSQL должен обновить *каждый* индекс на таблице. Это огромное количество случайных операций ввода-вывода, которые замедляют процесс в разы. Гораздо быстрее загрузить все данные в \"голую\" таблицу, а затем одной командой `CREATE INDEX` построить индекс. Эта операция выполняет одну последовательную читку таблицы и строит индекс гораздо эффективнее.\n",
    "          * **Внешние ключи (FK):** При вставке каждой строки СУБД должна проверить наличие соответствующего ключа в связанной таблице. Это еще одна операция поиска на каждую строку. Проверка `ALTER TABLE ... VALIDATE CONSTRAINT` после загрузки всех данных делает это один раз для всей таблицы.\n",
    "          * **Триггеры:** Отключение триггеров избавляет от накладных расходов на их запуск для каждой строки.\n",
    "      * **Примерный воркфлоу:**\n",
    "        ```sql\n",
    "        BEGIN;\n",
    "        -- 1. Удаляем индексы и FK\n",
    "        DROP INDEX IF EXISTS idx_employees_department;\n",
    "        ALTER TABLE employees DROP CONSTRAINT fk_department;\n",
    "\n",
    "        -- 2. Загружаем данные\n",
    "        COPY employees FROM 'massive_data.csv' WITH CSV;\n",
    "\n",
    "        -- 3. Воссоздаем индексы и FK\n",
    "        CREATE INDEX idx_employees_department ON employees(department);\n",
    "        ALTER TABLE employees ADD CONSTRAINT fk_department FOREIGN KEY (...) REFERENCES ...;\n",
    "        COMMIT;\n",
    "        ```\n",
    "\n",
    "3.  **Настройка памяти:** Перед воссозданием индексов увеличьте параметр `maintenance_work_mem` для вашей сессии. Это позволит PostgreSQL выделить больше оперативной памяти для операции построения индекса, что значительно ее ускорит.\n",
    "\n",
    "    ```sql\n",
    "    SET maintenance_work_mem = '2GB'; -- Установите значение в зависимости от доступной RAM\n",
    "    CREATE INDEX ...;\n",
    "    ```\n",
    "\n",
    "4.  **Параллелизм:** Эта опция относится к `pg_restore`. При восстановлении из дампа формата `custom` (`-Fc`) используйте флаг `-j` (или `--jobs`), чтобы запустить несколько процессов восстановления параллельно. Это может кратно ускорить процесс на многоядерных серверах.\n",
    "\n",
    "    ```bash\n",
    "    pg_restore -j 8 -d new_db mydb.dump\n",
    "    ```\n",
    "\n",
    "-----\n",
    "\n",
    "## 5\\. Инструменты логического бэкапа: pg\\_dump и pg\\_restore\n",
    "\n",
    "Эти утилиты — ваш швейцарский нож для миграций, бэкапов и клонирования.\n",
    "\n",
    "### Сравнение форматов (`-F`)\n",
    "\n",
    "  * **`plain` (`-Fp`, по умолчанию):** Создает большой текстовый `.sql` файл.\n",
    "      * **Плюсы:** Человекочитаемый, можно редактировать, легко отслеживать изменения в Git.\n",
    "      * **Минусы:** Огромный размер, медленное восстановление (только в один поток), нет гибкости.\n",
    "  * **`tar` (`-Ft`):** Создает `.tar` архив.\n",
    "      * **Плюсы:** Позволяет выборочно восстанавливать объекты.\n",
    "      * **Минусы:** Не сжат, во многом уступает формату `custom`.\n",
    "  * **`custom` (`-Fc`):** **Рекомендуемый формат для большинства задач.**\n",
    "      * **Плюсы:** Сжат по умолчанию, включает и схему, и данные, позволяет **параллельное восстановление** (`-j`), позволяет **выборочно восстанавливать** таблицы, схемы или только данные/схему.\n",
    "      * **Минусы:** Не человекочитаемый, требует `pg_restore` для использования.\n",
    "\n",
    "### Сценарии использования (с примерами команд)\n",
    "\n",
    "  * **Дамп всей БД в формате custom:**\n",
    "    ```bash\n",
    "    pg_dump -U postgres -h localhost -Fc --verbose -f my_database.dump my_database\n",
    "    ```\n",
    "  * **Восстановление всей БД из дампа:**\n",
    "    ```bash\n",
    "    # Сначала нужно создать пустую базу\n",
    "    createdb -U postgres new_database\n",
    "    pg_restore -U postgres -h localhost -d new_database -j 8 my_database.dump\n",
    "    ```\n",
    "  * **Дамп только схемы (структуры):**\n",
    "    ```bash\n",
    "    pg_dump -U postgres -s -f schema.sql my_database\n",
    "    ```\n",
    "  * **Дамп только данных (без схемы):**\n",
    "    ```bash\n",
    "    pg_dump -U postgres -a -f data.sql my_database\n",
    "    ```\n",
    "  * **Выборочное восстановление (Selective Restore):**\n",
    "      * Сначала посмотрим содержимое дампа:\n",
    "        ```bash\n",
    "        pg_restore -l my_database.dump > dump_contents.txt\n",
    "        ```\n",
    "      * Затем восстановим только таблицу `public.employees`:\n",
    "        ```bash\n",
    "        pg_restore -U postgres -d new_database -t employees my_database.dump\n",
    "        ```\n",
    "  * **Дамп всего кластера (`pg_dumpall`):**\n",
    "    Эта утилита нужна для бэкапа **глобальных объектов**, которые не принадлежат конкретной базе данных: ролей (пользователей) и табличных пространств. Стандартный воркфлоу для полного бэкапа кластера:\n",
    "    ```bash\n",
    "    # 1. Дампим глобальные объекты\n",
    "    pg_dumpall -U postgres --globals-only > globals.sql\n",
    "\n",
    "    # 2. Дампим каждую базу данных отдельно (можно в цикле)\n",
    "    pg_dump -U postgres -Fc -f db1.dump db1\n",
    "    pg_dump -U postgres -Fc -f db2.dump db2\n",
    "    ```\n",
    "\n",
    "-----\n",
    "\n",
    "## 6\\. Интеграция, автоматизация и экосистема\n",
    "\n",
    "### `psql` в скриптах\n",
    "\n",
    "`psql` — мощный инструмент для автоматизации.\n",
    "\n",
    "  * `-c \"command\"`: Выполнить одну команду и выйти.\n",
    "    ```bash\n",
    "    psql -U postgres -d mydb -c \"SELECT count(*) FROM users;\"\n",
    "    ```\n",
    "  * `-f script.sql`: Выполнить команды из файла.\n",
    "    ```bash\n",
    "    psql -U postgres -d mydb -f /path/to/my_script.sql\n",
    "    ```\n",
    "\n",
    "### Пример Bash-скрипта для автоматизации бэкапа\n",
    "\n",
    "Этот скрипт делает полный дамп схемы и выгружает ключевую таблицу в CSV для архивации.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -e # Прервать выполнение при любой ошибке\n",
    "\n",
    "# --- Настройки ---\n",
    "DB_USER=\"postgres\"\n",
    "DB_NAME=\"production_db\"\n",
    "BACKUP_DIR=\"/var/backups/postgresql\"\n",
    "DATE=$(date +\"%Y-%m-%d_%H%M\")\n",
    "\n",
    "# --- Создание директории бэкапа ---\n",
    "mkdir -p \"$BACKUP_DIR\"\n",
    "\n",
    "# --- 1. Дамп схемы ---\n",
    "echo \"Dumping schema...\"\n",
    "pg_dump -U \"$DB_USER\" -d \"$DB_NAME\" --schema-only -f \"$BACKUP_DIR/schema-$DATE.sql\"\n",
    "\n",
    "# --- 2. Выгрузка критически важных данных в CSV ---\n",
    "echo \"Exporting critical 'transactions' table to CSV...\"\n",
    "psql -U \"$DB_USER\" -d \"$DB_NAME\" -c \"\\copy (SELECT * FROM transactions WHERE created_at > NOW() - INTERVAL '1 day') TO '$BACKUP_DIR/transactions-$DATE.csv' WITH CSV HEADER\"\n",
    "\n",
    "# --- 3. Архивирование ---\n",
    "echo \"Creating archive...\"\n",
    "tar -czf \"$BACKUP_DIR/backup-$DATE.tar.gz\" -C \"$BACKUP_DIR\" \"schema-$DATE.sql\" \"transactions-$DATE.csv\"\n",
    "\n",
    "# --- 4. Очистка временных файлов ---\n",
    "rm \"$BACKUP_DIR/schema-$DATE.sql\" \"$BACKUP_DIR/transactions-$DATE.csv\"\n",
    "\n",
    "# --- 5. Удаление старых бэкапов (старше 7 дней) ---\n",
    "find \"$BACKUP_DIR\" -type f -name \"*.tar.gz\" -mtime +7 -delete\n",
    "\n",
    "echo \"Backup complete: $BACKUP_DIR/backup-$DATE.tar.gz\"\n",
    "```\n",
    "\n",
    "### Сторонние инструменты и языки\n",
    "\n",
    "  * **Python:**\n",
    "      * **`psycopg2`:** Для максимальной производительности используйте `cursor.copy_expert()` или `cursor.copy_from()`. Это позволяет потоково передавать данные из вашего приложения прямо в `COPY STDIN`, минуя создание промежуточных файлов.\n",
    "      * **`pandas` + `sqlalchemy`:** Для ETL и аналитических задач `DataFrame.to_sql(method='multi')` является удобной оберткой, но для очень больших объемов прямой `COPY` через `psycopg2` будет быстрее.\n",
    "  * **Графические инструменты:** `pgAdmin` и `DBeaver` имеют удобные GUI для импорта/экспорта. Важно понимать, что под капотом они генерируют и выполняют те же самые команды `COPY`/`\\copy`.\n",
    "\n",
    "-----\n",
    "\n",
    "## 7\\. Безопасность и итоги\n",
    "\n",
    "### Безопасность, кодировка и документирование\n",
    "\n",
    "  * **Документирование:** Всегда сохраняйте команду `pg_dump`, которой был сделан бэкап. Это поможет избежать ошибок при восстановлении (например, забыть про флаг `--no-owner`).\n",
    "  * **Шифрование:** Если ваши дампы содержат чувствительные данные (PII), шифруйте их перед отправкой в хранилище (например, S3).\n",
    "    ```bash\n",
    "    pg_dump -Fc ... | gpg -c -o backup.dump.gpg\n",
    "    ```\n",
    "  * **Кодировка (Encoding):** 99% проблем с кириллицей и другими не-латинскими символами решаются правильной настройкой кодировки. Убедитесь, что ваша база создана в `UTF8`. При работе с `psql` переменная окружения `PGCLIENTENCODING` должна быть установлена в `UTF8`. При `COPY` можно явно указать кодировку: `COPY ... FROM 'file.csv' WITH (ENCODING 'UTF8')`.\n",
    "\n",
    "### Чек-лист для импорта больших данных в Production\n",
    "\n",
    "Перед тем как запустить импорт гигабайтов данных на боевом сервере, пройдитесь по этому списку:\n",
    "\n",
    "1.  [ ] **Бэкап:** Сделан ли свежий, проверенный бэкап целевой базы данных?\n",
    "2.  [ ] **Место на диске:** Достаточно ли места для самих данных, WAL-файлов и для построения новых индексов? (Построение индекса требует дополнительного места, сопоставимого с размером самого индекса).\n",
    "3.  [ ] **Транзакция:** Вся операция импорта обернута в `BEGIN...COMMIT`?\n",
    "4.  [ ] **Отключение:** Отключены (или удалены) ли все некритичные индексы, внешние ключи и триггеры на целевой таблице?\n",
    "5.  [ ] **Память:** Увеличен ли `maintenance_work_mem` для сессии перед созданием индексов?\n",
    "6.  [ ] **Мониторинг:** Настроен ли мониторинг нагрузки на CPU, I/O и потребления дискового пространства на время операции?\n",
    "7.  [ ] **План отката:** Что вы будете делать, если что-то пойдет не так?\n",
    "\n",
    "Надеюсь, это руководство станет вашим верным спутником в мире PostgreSQL. Удачи\\! 🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
