{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883c7143",
   "metadata": {},
   "source": [
    "### Решение Задания 1: Основы `\\copy` (Экспорт и Импорт)\n",
    "\n",
    "**1. Экспорт:**\n",
    "\n",
    "Откройте терминал и подключитесь к вашей базе данных `northwind` с помощью `psql`.\n",
    "\n",
    "```bash\n",
    "psql -d northwind\n",
    "```\n",
    "\n",
    "Теперь выполните команду экспорта. Мы явно перечисляем столбцы, чтобы исключить `discontinued`.\n",
    "\n",
    "```sql\n",
    "\\copy (SELECT product_id, product_name, supplier_id, category_id, quantity_per_unit, unit_price, units_in_stock, units_on_order, reorder_level FROM products) TO 'products_export.csv' WITH (FORMAT CSV, HEADER, DELIMITER ';', NULL '(not set)');\n",
    "```\n",
    "\n",
    "**2. Импорт и проверка:**\n",
    "\n",
    "Сначала создаем таблицу-копию:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE products_copy (LIKE products INCLUDING ALL);\n",
    "```\n",
    "\n",
    "Затем импортируем данные из файла, который мы только что создали. Настройки (`DELIMITER`, `NULL` и т.д.) должны в точности соответствовать тем, что использовались при экспорте.\n",
    "\n",
    "```sql\n",
    "\\copy products_copy FROM 'products_export.csv' WITH (FORMAT CSV, HEADER, DELIMITER ';', NULL '(not set)');\n",
    "```\n",
    "\n",
    "**Проверка:**\n",
    "\n",
    "Выполним подсчет строк в обеих таблицах. Результат должен быть одинаковым.\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(*) FROM products;\n",
    "--  count\n",
    "-- -------\n",
    "--     77\n",
    "--(1 row)\n",
    "\n",
    "SELECT COUNT(*) FROM products_copy;\n",
    "--  count\n",
    "-- -------\n",
    "--     77\n",
    "--(1 row)\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### Решение Задания 2: Продвинутый экспорт с использованием запроса\n",
    "\n",
    "Эта команда объединяет три таблицы (`orders`, `order_details` и `products`), фильтрует заказы по 1997 году и выгружает результат напрямую в CSV файл.\n",
    "\n",
    "```sql\n",
    "\\copy (\n",
    "    SELECT\n",
    "        o.order_id,\n",
    "        o.order_date,\n",
    "        p.product_name,\n",
    "        od.quantity,\n",
    "        od.unit_price\n",
    "    FROM\n",
    "        orders o\n",
    "    JOIN\n",
    "        order_details od ON o.order_id = od.order_id\n",
    "    JOIN\n",
    "        products p ON od.product_id = p.product_id\n",
    "    WHERE\n",
    "        EXTRACT(YEAR FROM o.order_date) = 1997\n",
    ") TO 'sales_report_1997.csv' WITH (FORMAT CSV, HEADER);\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### Решение Задания 3: Импорт с обработкой ошибок (Staging Table)\n",
    "\n",
    "**1. Создание Staging-таблицы:**\n",
    "\n",
    "Мы используем `TEMP TABLE`, чтобы она автоматически удалилась после завершения сессии. Все поля имеют тип `TEXT` для \"безопасной\" загрузки любых данных.\n",
    "\n",
    "```sql\n",
    "CREATE TEMP TABLE suppliers_staging (\n",
    "    supplier_name TEXT,\n",
    "    contact_name TEXT,\n",
    "    city TEXT,\n",
    "    country TEXT,\n",
    "    phone TEXT\n",
    ");\n",
    "```\n",
    "\n",
    "**2. Загрузка \"грязных\" данных:**\n",
    "\n",
    "Сохраните предоставленные CSV данные в файл `new_suppliers.csv` и выполните команду:\n",
    "\n",
    "```sql\n",
    "\\copy suppliers_staging FROM 'new_suppliers.csv' WITH (FORMAT CSV);\n",
    "```\n",
    "\n",
    "**3. Очистка и вставка в основную таблицу:**\n",
    "\n",
    "Это самый важный шаг. Мы используем `INSERT INTO ... SELECT`, чтобы преобразовать и отфильтровать данные \"на лету\".\n",
    "\n",
    "```sql\n",
    "INSERT INTO suppliers (company_name, contact_name, city, country, phone)\n",
    "SELECT\n",
    "    supplier_name,\n",
    "    NULLIF(contact_name, ''),  -- Превращает пустую строку '' в NULL\n",
    "    city,\n",
    "    country,\n",
    "    NULLIF(phone, '')          -- Превращает пустую строку '' в NULL\n",
    "FROM\n",
    "    suppliers_staging\n",
    "WHERE\n",
    "    country <> '??'; -- Отфильтровываем невалидную строку\n",
    "```\n",
    "\n",
    "**4. Проверка:**\n",
    "\n",
    "Теперь посмотрим на последние добавленные записи в таблице `suppliers`. Они должны быть чистыми и корректными.\n",
    "\n",
    "```sql\n",
    "SELECT * FROM suppliers ORDER BY supplier_id DESC LIMIT 3;\n",
    "```\n",
    "\n",
    "Результат покажет три новые записи с корректными `NULL` значениями и без строки `\"Invalid Data\"`.\n",
    "\n",
    "-----\n",
    "\n",
    "### Решение Задания 4: Работа с `pg_dump` и `pg_restore`\n",
    "\n",
    "**1. Создание бэкапа:**\n",
    "\n",
    "Эта команда выполняется в вашем системном терминале (не в `psql`). Замените `your_user` на ваше имя пользователя PostgreSQL.\n",
    "\n",
    "```bash\n",
    "pg_dump -U your_user -Fc -f northwind.dump northwind\n",
    "```\n",
    "\n",
    "Вам будет предложено ввести пароль. После выполнения команды в текущей директории появится файл `northwind.dump`.\n",
    "\n",
    "**2. Выборочное восстановление:**\n",
    "\n",
    "Сначала создаем новую пустую базу данных:\n",
    "\n",
    "```bash\n",
    "createdb -U your_user northwind_partial_restore\n",
    "```\n",
    "\n",
    "Теперь используем `pg_restore` с флагом `-t` для каждой таблицы, которую хотим восстановить.\n",
    "\n",
    "```bash\n",
    "pg_restore -U your_user -d northwind_partial_restore -t employees -t customers northwind.dump\n",
    "```\n",
    "\n",
    "**Проверка:**\n",
    "\n",
    "Подключитесь к новой базе и выведите список таблиц. Вы должны увидеть только `employees` и `customers`.\n",
    "\n",
    "```bash\n",
    "psql -d northwind_partial_restore\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Внутри сессии psql\n",
    "\\dt\n",
    "--             List of relations\n",
    "-- Schema |   Name    | Type  |   Owner\n",
    "-- --------+-----------+-------+----------\n",
    "-- public | customers | table | your_user\n",
    "-- public | employees | table | your_user\n",
    "--(2 rows)\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### Решение Задания 5: Оптимизация производительности (Теоретический вопрос)\n",
    "\n",
    "Вот мой пошаговый план действий для максимально быстрой загрузки 50 миллионов записей в таблицу `order_details`:\n",
    "\n",
    "**Шаг 1: Начать транзакцию**\n",
    "\n",
    "  * **Действие:** Выполнить команду `BEGIN;`.\n",
    "  * **Почему это ускоряет:** Оборачивание всей операции в одну транзакцию минимизирует транзакционные издержки. Вместо 50 миллионов мелких транзакций СУБД выполняет одну большую, что значительно снижает нагрузку на запись в WAL (Write-Ahead Log).\n",
    "\n",
    "**Шаг 2: Удалить все внешние ключи и индексы (кроме Primary Key)**\n",
    "\n",
    "  * **Действие:** Выполнить `ALTER TABLE order_details DROP CONSTRAINT fk_orders;`, `ALTER TABLE order_details DROP CONSTRAINT fk_products;`, `DROP INDEX idx_quantity;`.\n",
    "  * **Почему это ускоряет:** Это **самый важный** шаг.\n",
    "      * **Внешние ключи:** Без них PostgreSQL не нужно для каждой из 50 млн строк выполнять проверку (lookup) в таблицах `orders` и `products`.\n",
    "      * **Индексы:** При вставке каждой строки СУБД должна обновлять каждый существующий индекс. Это вызывает огромное количество медленных, случайных операций дискового ввода-вывода. Загрузка в \"голую\" таблицу — это быстрая последовательная запись.\n",
    "\n",
    "**Шаг 3: Выполнить загрузку данных**\n",
    "\n",
    "  * **Действие:** Использовать команду `COPY order_details FROM 'massive_file.csv' WITH (FORMAT CSV);`.\n",
    "  * **Почему это ускоряет:** `COPY` — это самый быстрый нативный механизм загрузки данных в PostgreSQL, так как он работает на низком уровне с минимальными накладными расходами.\n",
    "\n",
    "**Шаг 4: Воссоздать индексы и внешние ключи**\n",
    "\n",
    "  * **Действие:** Увеличить `maintenance_work_mem` (`SET maintenance_work_mem = '2GB';`), затем выполнить `CREATE INDEX idx_quantity ON order_details(quantity);` и `ALTER TABLE order_details ADD CONSTRAINT ...;`.\n",
    "  * **Почему это ускоряет:**\n",
    "      * Построение индекса \"с нуля\" для уже заполненной таблицы — это одна эффективная операция последовательного чтения, которая выполняется гораздо быстрее, чем 50 миллионов мелких обновлений индекса.\n",
    "      * Увеличение `maintenance_work_mem` позволяет PostgreSQL строить индекс в оперативной памяти, что многократно ускоряет процесс.\n",
    "      * Проверка внешнего ключа после загрузки также выполняется одной массовой, более оптимизированной операцией для всей таблицы.\n",
    "\n",
    "**Шаг 5: Завершить транзакцию**\n",
    "\n",
    "  * **Действие:** Выполнить команду `COMMIT;`.\n",
    "  * **Почему это важно:** Это атомарно фиксирует все изменения. Если на любом из предыдущих шагов произойдет сбой, вся транзакция откатится, и база данных останется в исходном, чистом состоянии.\n",
    "\n",
    "-----\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
